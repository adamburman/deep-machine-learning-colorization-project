{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3985f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME1 = \"Caroline Andersson\" \n",
    "NAME2 = \"Adam Burman\"\n",
    "GROUP = \"84\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ea77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check Python version\n",
    "from platform import python_version_tuple\n",
    "assert python_version_tuple()[:2] == ('3','9'), \"You are not running Python 3.9. Make sure to run Python through the course Conda environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec2e61",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456aa90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = r\"C:\\Users\\carol\\Deep Machine Learning\\project\\Dataset\"\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Resize\n",
    "from pathlib import Path\n",
    "import torchvision.transforms\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "#import colorspacious as cs\n",
    "\n",
    "\n",
    "import kornia # https://kornia.readthedocs.io/en/latest/color.html\n",
    "#Lab color is computed using the D65 illuminant and Observer 2. (deafult in kornia)\n",
    "\n",
    "\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760df72-d1f1-4d85-8e5c-986972b61f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3200b3f5-ab66-4f73-bc09-ae510fad52ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813fdc9",
   "metadata": {},
   "source": [
    "### 1.2 Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf68f95",
   "metadata": {},
   "source": [
    "Make a dataloader class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1db943-0d6b-44ef-a76f-eeeff996432c",
   "metadata": {},
   "source": [
    "### 1.2.1 Load GTA Data and Return L, ab // or [1, s, s], [2, s, s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576071b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from itertools import chain\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "class GTALabData(Dataset):\n",
    "    \n",
    "\n",
    "    def __init__(self, root, transform = None):\n",
    "            \"\"\"Constructor\n",
    "        \n",
    "        Args:\n",
    "            root (Path/str): Filepath to the data root\n",
    "            transform (Compose): A composition of image transforms.\n",
    "        \"\"\"\n",
    "            root = Path(root)\n",
    "            if not (root.exists() and root.is_dir()):\n",
    "                raise ValueError(f\"Data root '{root}' is invalid\")\n",
    "            \n",
    "            self.root = root\n",
    "            self.transform = transform\n",
    "            self.img_paths, self.label_paths = self._collect_samples()\n",
    "            \n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get sample by index\n",
    "        \n",
    "        Args:\n",
    "            index (int)\n",
    "        \n",
    "        Returns:\n",
    "             The index'th sample Tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        img_path = self.img_paths[index]\n",
    "        label_path = self.label_paths[index]\n",
    "\n",
    "        # Load the image and label into memory\n",
    "        img = Image.open(img_path)\n",
    "        #label = Image.open(label_path)\n",
    "        img1 = torchvision.transforms.functional.pil_to_tensor(img) # PIL --> Tensor\n",
    "        img = kornia.color.rgb_to_lab(img1/255) # RGB --> Lab\n",
    "        \n",
    "        L = img[0]#kornia.color.rgb_to_grayscale(img1/255)#img[0]\n",
    "        a = img[1]\n",
    "        b = img[2]\n",
    "\n",
    "        # Perform transforms, if any.\n",
    "        if self.transform is not None:\n",
    "            L = self.transform(L.numpy()) # transform L\n",
    "            a = self.transform(a.numpy()) # transform\n",
    "            b = self.transform(b.numpy()) # transform\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        ab = torch.cat((a.unsqueeze(0), b.unsqueeze(0)), dim=0).squeeze()\n",
    "        #L = torch.cat((L.unsqueeze(0), L.unsqueeze(0), L.unsqueeze(0)), dim=0).squeeze()\n",
    "\n",
    "        return (L-50)/50, ab/128\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of samples in the dataset\"\"\"\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def _collect_samples(self):\n",
    "        \"\"\"Collect all paths and labels\n",
    "        \n",
    "        Helper method for the constructor\n",
    "        \"\"\"\n",
    "        \"\"\"Collect all paths and labels\n",
    "\n",
    "        Helper method for the constructor\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Get image and label paths\n",
    "        img_dir = self.root / \"01_images\" / \"images\"\n",
    "        label_dir = self.root / \"01_labels\" / \"labels\"\n",
    "        \n",
    "        # check if there are images in the directory\n",
    "        #self._check_images_in_directory(img_dir)\n",
    "        #self._check_images_in_directory(label_dir)\n",
    "\n",
    "        img_paths = list(img_dir.glob(\"*.png\"))\n",
    "        label_paths = list(label_dir.glob(\"*.png\"))\n",
    "\n",
    "        if len(img_paths) != len(label_paths):\n",
    "            raise ValueError(\"Number of images and labels must be the same\")\n",
    "            \n",
    "        return img_paths, label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306e825c-691d-43db-bebb-1d4d5248d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "torch.float32\n",
      "torch.Size([1, 1052, 1914])\n",
      "torch.Size([2, 1052, 1914])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = Compose([ToTensor()])\n",
    "\n",
    "example_dataset = GTALabData(path, transform)\n",
    "print(len(example_dataset)) #1\n",
    "L, ab = example_dataset[2]\n",
    "#print(img)\n",
    "print(L.dtype)\n",
    "print(L.shape)\n",
    "print(ab.shape)\n",
    "print(np.max(L.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16080e99-63dc-4dcf-b400-bb29e6b8b026",
   "metadata": {},
   "source": [
    "### 1.2.1 Load GTA Data and Return L, segmented image // or [1, s, s], [1, s, s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a76855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GTASemanticData\n",
    "# Note: there are 19 semantic classes\n",
    "from torch.utils.data import Dataset\n",
    "from itertools import chain\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "class GTASemData(Dataset):\n",
    "    \n",
    "\n",
    "    def __init__(self, root, transform = None):\n",
    "            \"\"\"Constructor\n",
    "        \n",
    "        Args:\n",
    "            root (Path/str): Filepath to the data root\n",
    "            transform (Compose): A composition of image transforms.\n",
    "        \"\"\"\n",
    "            root = Path(root)\n",
    "            if not (root.exists() and root.is_dir()):\n",
    "                raise ValueError(f\"Data root '{root}' is invalid\")\n",
    "            \n",
    "            self.root = root\n",
    "            self.transform = transform\n",
    "            self.img_paths, self.label_paths = self._collect_samples()\n",
    "            \n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get sample by index\n",
    "        \n",
    "        Args:\n",
    "            index (int)\n",
    "        \n",
    "        Returns:\n",
    "             The index'th sample Tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        img_path = self.img_paths[index]\n",
    "        label_path = self.label_paths[index]\n",
    "\n",
    "        # Load the image and label into memory\n",
    "        img = Image.open(img_path)\n",
    "        label = Image.open(label_path)\n",
    "        \n",
    "        \n",
    "        img1 = torchvision.transforms.functional.pil_to_tensor(img) # PIL --> Tensor\n",
    "        img = kornia.color.rgb_to_lab(img1/255) # RGB --> Lab\n",
    "        \n",
    "        L = img[0]\n",
    "        a = img[1]\n",
    "        b = img[2]\n",
    "\n",
    "        # Perform transforms, if any.\n",
    "        if self.transform is not None:\n",
    "            L = self.transform(L.numpy()) # transform L\n",
    "            label = self.transform(label) # transform\n",
    "            a = self.transform(a.numpy()) # transform\n",
    "            b = self.transform(b.numpy()) # transform\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        ab = torch.cat((a.unsqueeze(0), b.unsqueeze(0)), dim=0).squeeze()\n",
    "        out = torch.cat(((L.unsqueeze(0)-50)/50, label.unsqueeze(0)), dim=0).squeeze()\n",
    "\n",
    "        return (L-50)/50, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of samples in the dataset\"\"\"\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def _collect_samples(self):\n",
    "        \"\"\"Collect all paths and labels\n",
    "        \n",
    "        Helper method for the constructor\n",
    "        \"\"\"\n",
    "        \"\"\"Collect all paths and labels\n",
    "\n",
    "        Helper method for the constructor\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Get image and label paths\n",
    "        img_dir = self.root / \"01_images\" / \"images\"\n",
    "        label_dir = self.root / \"01_labels\" / \"labels\"\n",
    "        \n",
    "        # check if there are images in the directory\n",
    "        #self._check_images_in_directory(img_dir)\n",
    "        #self._check_images_in_directory(label_dir)\n",
    "\n",
    "        img_paths = list(img_dir.glob(\"*.png\"))\n",
    "        label_paths = list(label_dir.glob(\"*.png\"))\n",
    "\n",
    "        if len(img_paths) != len(label_paths):\n",
    "            raise ValueError(\"Number of images and labels must be the same\")\n",
    "            \n",
    "        return img_paths, label_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ba0fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 223.5, 223.5, -0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize_size = 224\n",
    "transform =  Compose([ToTensor(), Resize((resize_size, resize_size), antialias=True)])\n",
    "\n",
    "example_dataset1 = GTASemData(path, transform)\n",
    "L1, s = example_dataset1[1]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(s.numpy().squeeze())\n",
    "plt.title('Semantic Image')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c30903-7697-464b-be12-e9f0468878cb",
   "metadata": {},
   "source": [
    "### 1.3 Augument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1a9a55a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9615413\n"
     ]
    }
   ],
   "source": [
    "# Dataset \n",
    "mean = 52.37087932\n",
    "std = 24.64118381\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13465bbe",
   "metadata": {},
   "source": [
    "### 1.5 Chop up into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "456f4e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9710671\n",
      "-0.9831371\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Calculate mean std\n",
    "temp_dataset = GTALabData(path, ToTensor())\n",
    "\n",
    "#test_img,_ = gta_dataset[0]\n",
    "#print(test_img)\n",
    "'''\n",
    "number_of_samples = len(temp_dataset)\n",
    "dataset_mean = []\n",
    "dataset_std = []\n",
    "for image,_ in temp_dataset:\n",
    "    imgArray = np.array(image)\n",
    "    #print(imgArray)\n",
    "    dataset_mean.append(np.mean(imgArray))\n",
    "    dataset_std.append(np.std(imgArray))\n",
    "\n",
    "print(np.min(dataset_mean))\n",
    "dataset_mean = np.mean(dataset_mean)\n",
    "dataset_std = np.mean(dataset_std)\n",
    "'''\n",
    "mean = 52.37087932\n",
    "std = 24.64118381\n",
    "img_size = 128#224\n",
    "#gta_transform = Compose([ToTensor(), Resize((img_size, img_size), antialias=True), Normalize(mean, std, inplace=False)]) \n",
    "gta_transform = Compose([ToTensor(), Resize((img_size, img_size), antialias=True)])\n",
    "gta_dataset = GTALabData(path, gta_transform)\n",
    "\n",
    "test_img, ab = gta_dataset[0]\n",
    "print(np.max(test_img.numpy()))\n",
    "print(np.min(test_img.numpy()))\n",
    "\n",
    "\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "n_samples = len(gta_dataset)\n",
    "n_val_samples = int(n_samples * val_ratio)\n",
    "n_test_samples = int(n_samples * test_ratio)\n",
    "n_train_samples = n_samples - n_val_samples - n_test_samples\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    gta_dataset, [n_train_samples, n_val_samples, n_test_samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b471bb",
   "metadata": {},
   "source": [
    "##  2. Create an Autoenconder for the Raw images\n",
    "vgg16 can be used as the encoder by using transfer learning with the gtaV images. Then a decoder has to be constructed from scratch to generate a new image. The raw images are used in this section and later on another autoencoder will be trained with segmented images (our labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233edc1",
   "metadata": {},
   "source": [
    "### 2.1 Create the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a84c1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Endocer\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, return_indices=True)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # Output has 2 channels (ab color channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        #Decoder\n",
    "        \n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.tc1 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.tc2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.tc3 = nn.Conv2d(64, 2, kernel_size=3, padding=1)  # Output has 2 channels (ab color channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        #x, indices = self.pool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        \n",
    "        # Decoder\n",
    "        \n",
    "        x = self.tc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.tc2(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.unpool(x, indices)\n",
    "        x = self.tc3(x)\n",
    "        \n",
    "        \n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        # Perform upsampling to the desired size [1052, 1914]\n",
    "        #x = F.interpolate(x, size=(1052, 1914), mode='bilinear', align_corners=False)\n",
    "       \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78625776",
   "metadata": {},
   "source": [
    "### 2.2 Freeze and Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "17627c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = nn.Sequential(vgg_model.features, VGG_head())\n",
    "#print(base_model.parameters)\n",
    "# Freeze all the parameters in the VGG16 model\n",
    "#for param in base_model.parameters():\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68d7e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every):\n",
    "    print(\"Starting training\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model, train_loss = train_epoch(model, optimizer, loss_fn, train_loader, device, print_every)\n",
    "        val_loss = validate(model, loss_fn, val_loader, device)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: \"\n",
    "              f\"Train loss: {train_loss:.3f}, \"\n",
    "              f\"Val. loss: {val_loss:.3f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "def train_epoch(model, optimizer, loss_fn, train_loader, device, print_every):\n",
    "    model.train()\n",
    "    train_loss_batches = []\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    for batch_index, (x, y) in enumerate(train_loader, 1):\n",
    "        inputs, labels = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z = model(inputs)\n",
    "        loss = loss_fn(z, labels)\n",
    "        #print(np.min(z.detach().cpu().numpy())) #kan max bli 1????\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_batches.append(loss.item())\n",
    "\n",
    "        if print_every is not None and batch_index % print_every == 0:\n",
    "            model.train()\n",
    "            print(f\"Batch {batch_index}/{num_batches}: Train loss: {sum(train_loss_batches[-print_every:])/print_every:.3f}\")\n",
    "\n",
    "    return model, sum(train_loss_batches) / len(train_loss_batches)\n",
    "\n",
    "def validate(model, loss_fn, val_loader, device):\n",
    "    val_loss_cum = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (x, y) in enumerate(val_loader, 1):\n",
    "            inputs, labels = x.to(device), y.to(device)\n",
    "            z = model(inputs)\n",
    "            batch_loss = loss_fn(z, labels)\n",
    "            val_loss_cum += batch_loss.item()\n",
    "    return val_loss_cum / len(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8721917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Batch 1/55: Train loss: 0.004\n",
      "Batch 2/55: Train loss: 0.023\n",
      "Batch 3/55: Train loss: 0.004\n",
      "Batch 4/55: Train loss: 0.004\n",
      "Batch 5/55: Train loss: 0.003\n",
      "Batch 6/55: Train loss: 0.003\n",
      "Batch 7/55: Train loss: 0.004\n",
      "Batch 8/55: Train loss: 0.003\n",
      "Batch 9/55: Train loss: 0.003\n",
      "Batch 10/55: Train loss: 0.003\n",
      "Batch 11/55: Train loss: 0.003\n",
      "Batch 12/55: Train loss: 0.003\n",
      "Batch 13/55: Train loss: 0.003\n",
      "Batch 14/55: Train loss: 0.004\n",
      "Batch 15/55: Train loss: 0.003\n",
      "Batch 16/55: Train loss: 0.003\n",
      "Batch 17/55: Train loss: 0.004\n",
      "Batch 18/55: Train loss: 0.003\n",
      "Batch 19/55: Train loss: 0.003\n",
      "Batch 20/55: Train loss: 0.002\n",
      "Batch 21/55: Train loss: 0.003\n",
      "Batch 22/55: Train loss: 0.002\n",
      "Batch 23/55: Train loss: 0.003\n",
      "Batch 24/55: Train loss: 0.003\n",
      "Batch 25/55: Train loss: 0.003\n",
      "Batch 26/55: Train loss: 0.003\n",
      "Batch 27/55: Train loss: 0.003\n",
      "Batch 28/55: Train loss: 0.003\n",
      "Batch 29/55: Train loss: 0.003\n",
      "Batch 30/55: Train loss: 0.003\n",
      "Batch 31/55: Train loss: 0.002\n",
      "Batch 32/55: Train loss: 0.003\n",
      "Batch 33/55: Train loss: 0.003\n",
      "Batch 34/55: Train loss: 0.003\n",
      "Batch 35/55: Train loss: 0.003\n",
      "Batch 36/55: Train loss: 0.003\n",
      "Batch 37/55: Train loss: 0.003\n",
      "Batch 38/55: Train loss: 0.003\n",
      "Batch 39/55: Train loss: 0.003\n",
      "Batch 40/55: Train loss: 0.002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m     13\u001b[0m print_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 17\u001b[0m trained_gta_model, train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[94], line 8\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every)\u001b[0m\n\u001b[0;32m      5\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     model, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(model, loss_fn, val_loader, device)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal. loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[94], line 23\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, loss_fn, train_loader, device, print_every)\u001b[0m\n\u001b[0;32m     20\u001b[0m train_loss_batches \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_index, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     24\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[73], line 43\u001b[0m, in \u001b[0;36mGTALabData.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#label = Image.open(label_path)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m img1 \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpil_to_tensor(img) \u001b[38;5;66;03m# PIL --> Tensor\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mkornia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrgb_to_lab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# RGB --> Lab\u001b[39;00m\n\u001b[0;32m     45\u001b[0m L \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;66;03m#kornia.color.rgb_to_grayscale(img1/255)#img[0]\u001b[39;00m\n\u001b[0;32m     46\u001b[0m a \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\lib\\site-packages\\kornia\\color\\lab.py:40\u001b[0m, in \u001b[0;36mrgb_to_lab\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput size must have a shape of (*, 3, H, W). Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Convert from sRGB to Linear RGB\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m lin_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mrgb_to_linear_rgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m xyz_im: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m rgb_to_xyz(lin_rgb)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# normalize for D65 white point\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dml\\lib\\site-packages\\kornia\\color\\rgb.py:199\u001b[0m, in \u001b[0;36mrgb_to_linear_rgb\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput size must have a shape of (*, 3, H, W).Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m lin_rgb: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(image \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.04045\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.055\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.055\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.4\u001b[39;49m\u001b[43m)\u001b[49m, image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m12.92\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lin_rgb\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "batch_size = 32\n",
    "base_model = AutoEncoder()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(base_model.parameters(), lr =0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "num_epochs = 4\n",
    "print_every = 1\n",
    "\n",
    "\n",
    "    \n",
    "trained_gta_model, train_losses, val_losses = training_loop(base_model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da08811-d624-4ff5-ae74-bb93119ae16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c74718ca",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf8c56-283a-4302-a7d2-5d6920af8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_losses)\n",
    "plt.figure()\n",
    "plt.plot(range(0,len(train_losses)), train_losses)\n",
    "plt.plot(range(0,len(val_losses)), val_losses)\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_gta_model.eval()\n",
    "test_image = train_dataset[0][0]\n",
    "#print(test_image.shape)\n",
    "batch_size = 10\n",
    "# Iterate through the test data\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "counter = 0\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch  # You can ignore the labels\n",
    "    if counter == 3:\n",
    "        break\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = trained_gta_model(inputs.to(device))\n",
    "\n",
    "    # View the input and output images\n",
    "    for i in range(3):\n",
    "        input_img = inputs[i].squeeze().cpu()*50 + 50 # rescale [-1,1] --> [0, 100]\n",
    "        input_labels = labels[i].squeeze().cpu()*128 # rescale [-1,1] --> [-128, 128]\n",
    "        output_img = outputs[i].cpu()*128 # rescale [-1,1] --> [-128, 128]\n",
    "        print(np.max(output_img.numpy()))\n",
    "        \n",
    "\n",
    "        # Network computed image\n",
    "        color_img = torch.cat((input_img.unsqueeze(0) ,output_img[0].unsqueeze(0), output_img[1].unsqueeze(0)), dim=0).cpu() # restore Lab image\n",
    "        color_img = kornia.color.lab_to_rgb(color_img) #Lab --> RGB\n",
    "        color_img = color_img.permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "\n",
    "        # Original Image\n",
    "        input_labels = F.interpolate(input_labels.unsqueeze(1), size=(img_size, img_size), mode='bilinear', align_corners=False).squeeze(1).cpu()\n",
    "        original_color_image = torch.cat((input_img.unsqueeze(0) ,input_labels[0].unsqueeze(0), input_labels[1].unsqueeze(0)), dim=0)\n",
    "        original_color_image = kornia.color.lab_to_rgb(original_color_image)\n",
    "\n",
    "\n",
    "        # Display the input and output images side by side\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(input_img, cmap='gray')\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(color_img)\n",
    "        plt.title('Output Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(original_color_image.permute(1, 2, 0).numpy())\n",
    "        plt.title('Original Color')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "#output = trained_gta_model(test_image)\n",
    "#test_dataloader = DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0f790",
   "metadata": {},
   "source": [
    "## 3. Create a Network for Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "30d5d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Endocer\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, return_indices=True)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # Output has 2 channels (ab color channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        #Decoder\n",
    "        \n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.tc1 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.tc2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.tc3 = nn.Conv2d(64, 1, kernel_size=3, padding=1)  # Output has 2 channels (ab color channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        # Encoder\n",
    "        x = self.conv1(x)\n",
    "        #x, indices = self.pool(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        \n",
    "        # Decoder\n",
    "        \n",
    "        x = self.tc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.tc2(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.unpool(x, indices)\n",
    "        x = self.tc3(x)\n",
    "        \n",
    "        \n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        # Perform upsampling to the desired size [1052, 1914]\n",
    "        #x = F.interpolate(x, size=(1052, 1914), mode='bilinear', align_corners=False)\n",
    "       \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "70628a2b-ee93-4148-b04b-09d9d832ab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128]) torch.Size([1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "gta_seg_transform = Compose([ToTensor(), Resize((img_size, img_size), antialias=True)])\n",
    "gta_seg_dataset = GTASemData(path, gta_transform)\n",
    "img, label = gta_seg_dataset[0]\n",
    "\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "n_samples = len(gta_seg_dataset)\n",
    "n_val_samples = int(n_samples * val_ratio)\n",
    "n_test_samples = int(n_samples * test_ratio)\n",
    "n_train_samples = n_samples - n_val_samples - n_test_samples\n",
    "\n",
    "s_train_dataset, s_val_dataset, s_test_dataset = random_split(\n",
    "    gta_seg_dataset, [n_train_samples, n_val_samples, n_test_samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1beced88-f1cf-4fd1-a37d-6c7971d37069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 1/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 2/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 3/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 4/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 5/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 6/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 7/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 8/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 9/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 10/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 11/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 12/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 13/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 14/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 15/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 16/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 17/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 18/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 19/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 20/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 21/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 22/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 23/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 24/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 25/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 26/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 27/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 28/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 29/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 30/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 31/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 32/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 33/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 34/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 35/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 36/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 37/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 38/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 39/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 40/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 41/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 42/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 43/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 44/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 45/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 46/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 47/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 48/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 49/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 50/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 51/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 52/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 53/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "Batch 54/55: Train loss: 0.000\n",
      "torch.Size([22, 1, 128, 128])\n",
      "Batch 55/55: Train loss: 0.000\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([32, 1, 128, 128])\n",
      "torch.Size([23, 1, 128, 128])\n",
      "Epoch 1/1: Train loss: 0.000, Val. loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "seg_color_model = SegModel()\n",
    "\n",
    "train_loader = DataLoader(s_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(s_val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(seg_color_model.parameters(), lr =0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_epochs = 1\n",
    "print_every = 1\n",
    "\n",
    "\n",
    "    \n",
    "trained_seg_model, train_losses, val_losses = training_loop(seg_color_model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3cf4b-659a-4fd1-a98b-0fba6a9fc67d",
   "metadata": {},
   "source": [
    "## 3.2 Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f6246-5cb3-47f1-8290-a366012357af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_seg_model.eval()\n",
    "test_image = train_dataset[0][0]\n",
    "#print(test_image.shape)\n",
    "batch_size = 10\n",
    "# Iterate through the test data\n",
    "test_loader = DataLoader(sc_test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "counter = 0\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch  # You can ignore the labels\n",
    "    if counter == 3:\n",
    "        break\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = trained_gta_model(inputs.to(device))\n",
    "\n",
    "    # View the input and output images\n",
    "    for i in range(3):\n",
    "        input_img = inputs[i].squeeze().cpu()*50 + 50 # rescale [-1,1] --> [0, 100]\n",
    "        input_labels = labels[i].squeeze().cpu()*128 # rescale [-1,1] --> [-128, 128]\n",
    "        output_img = outputs[i].cpu()*128 # rescale [-1,1] --> [-128, 128]\n",
    "        print(np.max(output_img.numpy()))\n",
    "        print(np.max(input_labels.numpy()*128))\n",
    "        \n",
    "\n",
    "        # Network computed image\n",
    "        color_img = torch.cat((input_img[0].unsqueeze(0) ,output_img[0].unsqueeze(0), output_img[1].unsqueeze(0)), dim=0).cpu() # restore Lab image\n",
    "        color_img = kornia.color.lab_to_rgb(color_img) #Lab --> RGB\n",
    "        color_img = color_img.permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "\n",
    "        # Original Image\n",
    "        #input_labels = F.interpolate(input_labels.unsqueeze(1), size=(img_size, img_size), mode='bilinear', align_corners=False).squeeze(1).cpu()\n",
    "        original_color_image = torch.cat((input_img[0].unsqueeze(0) ,input_labels[0].unsqueeze(0), input_labels[1].unsqueeze(0)), dim=0)\n",
    "        original_color_image = kornia.color.lab_to_rgb(original_color_image)\n",
    "\n",
    "\n",
    "        # Display the input and output images side by side\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(input_img[0], cmap='gray')\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(color_img)\n",
    "        plt.title('Output Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(original_color_image.permute(1, 2, 0).numpy())\n",
    "        plt.title('Original Color')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffe934",
   "metadata": {},
   "source": [
    "## 4. Create an Autoencoder that uses the Network  in 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e92a20",
   "metadata": {},
   "source": [
    "Combine Semantic segmentation with a new autoencoder to colorize images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df7aba-5173-40a5-8931-49afbf908fae",
   "metadata": {},
   "source": [
    "### 4.1 Create Combined Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e3240469-ce37-4db9-9c92-be2b803c526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, segmentation_model, colorization_model):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.segmentation_model = SegModel\n",
    "        self.colorization_model = AutoEncoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward the input through the segmentation model\n",
    "        segmentation_output = self.segmentation_model(x)\n",
    "        \n",
    "        # Forward the segmentation output through the colorization model\n",
    "        colorization_output = self.colorization_model(segmentation_output)\n",
    "\n",
    "        return colorization_output, segmentation_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3566a6dc-c276-4772-8020-2ef376856ce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CombinedGTAData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gta__combined_transform \u001b[38;5;241m=\u001b[39m Compose([ToTensor(), Resize((img_size, img_size), antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m----> 2\u001b[0m gta_combined_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCombinedGTAData\u001b[49m(path, gta_transform)\n\u001b[0;32m      3\u001b[0m img, label \u001b[38;5;241m=\u001b[39m gta_seg_dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape, label\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CombinedGTAData' is not defined"
     ]
    }
   ],
   "source": [
    "gta__combined_transform = Compose([ToTensor(), Resize((img_size, img_size), antialias=True)])\n",
    "gta_combined_dataset = CombinedGTAData(path, gta_transform)\n",
    "img, label = gta_seg_dataset[0]\n",
    "print(img.shape, label.shape)\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "n_samples = len(gta_seg_dataset)\n",
    "n_val_samples = int(n_samples * val_ratio)\n",
    "n_test_samples = int(n_samples * test_ratio)\n",
    "n_train_samples = n_samples - n_val_samples - n_test_samples\n",
    "\n",
    "sc_train_dataset, sc_val_dataset, sc_test_dataset = random_split(\n",
    "    gta_seg_dataset, [n_train_samples, n_val_samples, n_test_samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53233d5-fef8-4e2e-a92e-f69b12741783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "seg_color_model = SegModel()\n",
    "\n",
    "train_loader = DataLoader(sc_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(sc_val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(seg_color_model.parameters(), lr =0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "num_epochs = 5\n",
    "print_every = 1\n",
    "\n",
    "\n",
    "    \n",
    "trained_gta_model, train_losses, val_losses = training_loop(seg_color_model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065c80e-e313-4427-a512-643794b87100",
   "metadata": {},
   "source": [
    "### 4.2 Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09924638-e328-48ee-b7eb-b874bfdf5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_gta_model.eval()\n",
    "test_image = train_dataset[0][0]\n",
    "#print(test_image.shape)\n",
    "batch_size = 10\n",
    "# Iterate through the test data\n",
    "test_loader = DataLoader(sc_test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "counter = 0\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch  # You can ignore the labels\n",
    "    if counter == 3:\n",
    "        break\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = trained_gta_model(inputs.to(device))\n",
    "\n",
    "    # View the input and output images\n",
    "    for i in range(3):\n",
    "        input_img = inputs[i].squeeze().cpu()*50 + 50 # rescale [-1,1] --> [0, 100]\n",
    "        input_labels = labels[i].squeeze().cpu()*128 # rescale [-1,1] --> [-128, 128]\n",
    "        output_img = outputs[i].cpu()*128 # rescale [-1,1] --> [-128, 128]\n",
    "        print(np.max(output_img.numpy()))\n",
    "        print(np.max(input_labels.numpy()*128))\n",
    "        \n",
    "\n",
    "        # Network computed image\n",
    "        color_img = torch.cat((input_img[0].unsqueeze(0) ,output_img[0].unsqueeze(0), output_img[1].unsqueeze(0)), dim=0).cpu() # restore Lab image\n",
    "        color_img = kornia.color.lab_to_rgb(color_img) #Lab --> RGB\n",
    "        color_img = color_img.permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "\n",
    "        # Original Image\n",
    "        #input_labels = F.interpolate(input_labels.unsqueeze(1), size=(img_size, img_size), mode='bilinear', align_corners=False).squeeze(1).cpu()\n",
    "        original_color_image = torch.cat((input_img[0].unsqueeze(0) ,input_labels[0].unsqueeze(0), input_labels[1].unsqueeze(0)), dim=0)\n",
    "        original_color_image = kornia.color.lab_to_rgb(original_color_image)\n",
    "\n",
    "\n",
    "        # Display the input and output images side by side\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(input_img[0], cmap='gray')\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(color_img)\n",
    "        plt.title('Output Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(original_color_image.permute(1, 2, 0).numpy())\n",
    "        plt.title('Original Color')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd900daa",
   "metadata": {},
   "source": [
    "## 5. Compare the Two Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08034f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
